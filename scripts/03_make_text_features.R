
#
# Make large set of features for the text corpus.

source( here::here( "scripts/00_setup.R" ) )

#### Prepare data for processing ####

load( here::here("data-generated/meta.RData") )

all.feats = subset(meta, select=c(ID, s_id, grade, subject))
all.equal(all.feats,
          subset(text, select=c(ID, s_id, grade, subject)), check.attributes=F)

# Create preliminary text features ----

feats = rcttext::generate_features(text$text,
                                   meta = all.feats,
                                   sent = TRUE,
                                   clean_features = FALSE,
                                   terms = "xxx",
                                   read = c("Flesch","Flesch.Kincaid", "ARI",
                                            "ELF", "meanWordSyllables"),
                                   ld=c("TTR","R","K"),
                                   ignore="s_id",
                                   verbose = TRUE )

all.feats = feats

# Load LIWC-generated features ----

# (This loads file generated by LIWC program and cleans it)
all.feats = rcttext::extract_liwc(file="data-generated/LIWC_main.csv",
                                  meta=all.feats,
                                  ID.liwc=c("s_id","grade","subject"),
                                  ID.meta=c("s_id","grade","subject"),
                                  clean=FALSE)
dim(all.feats)

# Calculate Word2Vec projections for each essay on 50 dimensions ----

glove.50d = textdata::embedding_glove6b(dimensions = 50)

all.feats = rcttext::extract_w2v( rcttext::clean_text(text$text.sc),
                                  meta = all.feats,
                                  model = glove.50d )


# Measure distances between each essay and corresponding reference text ----

load("data/ref_texts.RData")

all.refs = clean_text( all.refs )
essays = clean_text( text$text.sc )

names(all.refs) = ref.names
all.refs = all.refs[ c( "G1.sci.both", "G1.soc.both", "G2.sci", "G2.soc.both") ]
names(all.refs) <- str_replace( names(all.refs), ".both", "" )

all.dists = pairwise_distances(essays, all.refs, 
                               method="cosine" )

all.dists

glove.dists = pairwise_distances(essays, all.refs,
                                 method="w2v", model=glove.50d )

distances = bind_rows( tdm.raw.cosine = all.dists, glove.d50.cosine = glove.dists, .id="metric" )
head( distances )

tmp = subset(meta, select=c(s_id, subject, grade))
stopifnot( nrow(distances) == 2*nrow(tmp) )
all2 = bind_cols( rbind( tmp, tmp ),
                  distances )
head( all2 )

all3 <- all2 %>%
  mutate(
    dist = case_when(
          grade == 1 & subject == "science" ~ doc_G1.sci,
          grade == 1 & subject == "social" ~ doc_G1.soc,
          grade == 2 & subject == "science" ~ doc_G2.sci,
          grade == 2 & subject == "social" ~ doc_G2.soc
    ) ) %>%
  dplyr::select( -doc_G1.sci, -doc_G1.soc, -doc_G2.sci, -doc_G2.soc ) %>%
  pivot_wider( names_from = metric, values_from = dist )
all3

table(meta$grade,meta$subject)


# Merge with existing feature set
all.info = merge(all.feats, all3, by=c("s_id","grade","subject"))


# Clean up: Trash all extra variables in workspace ----

all.info = all.info %>% 
  relocate(ID, everything())

gdata::keep(all.info, text, meta, sure=TRUE)



# Add output from TAACO ----

all.info <- rcttext::extract_taaco("data-generated/taaco_main.csv",
                                   meta = all.info,
                                   ID.meta = "ID" )

all.info = all.info %>% select(-ends_with("_para"), -ends_with("_div_seg"))



# Save the final set of features ----

dim(all.info)
dim(meta)

# Missing values in our feature set?
table(apply(all.info,2,anyNA))

# Add the meta information back in
all.info = merge(meta, all.info, by=c("ID", "s_id","subject", "grade"))


all.info = all.info[with(all.info,order(s_id,subject)),]


names(all.info) = gsub(" ","_",names(all.info),fixed=T)

save(all.info, file="data-generated/all.info.RData")
