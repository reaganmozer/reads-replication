
#
# Make large set of features for the text corpus.

source( here::here( "scripts/setup.R" ) )

source( here::here( "scripts/utils.R") )

#### Prepare data for processing ####

load( here::here("data-generated/meta.RData") )

all.feats = subset(meta, select=c(s_id, grade, subject))
all.equal(all.feats,
          subset(text,select=c(s_id, grade,subject)), check.attributes=F)

# Create preliminary text features


feats = tada::generate_features(text$text,
                              meta = all.feats,
                              sent = TRUE,
                              clean_features = FALSE,
                              terms = "xxx",
                              read = c("Flesch","Flesch.Kincaid", "ARI", "ELF",
                                       "meanWordSyllables"),
                              ld=c("TTR","R","K"),
                              ignore="s_id",
                              verbose = TRUE )

#all.feats = cbind(all.feats, feats)
  # Old version did not use meta argument in call to generate_features
  # Now that it's used, this line isn't necessary,
  # but this approach SHOULD work... (currently it's breaking)
all.feats = feats

# Load LIWC-generated features
# (This loads file generated by LIWC program and cleans it)
all.feats = tada::extract_liwc(file="data-generated/LIWC_main.csv",
                 meta=all.feats,
                 ID.liwc=c("s_id","grade","subject"),
                 ID.meta=c("s_id","grade","subject"),
                 clean=FALSE)
dim(all.feats)

# Calculate Word2Vec projections for each essay on 50 dimensions
if ( TRUE ) {

  glove.50d = textdata::embedding_glove6b(dimensions = 50)

  all.feats = tada::extract_w2v( clean_text(text$text.sc),
                                 meta = all.feats,
                                 model = glove.50d )

}

# Measure distances between each essay and it's corresponding reference text(s) and add to features
load("data/ref_texts.RData")
essays = text$text # used to be all.text but object doesn't exist
n.refs = length(all.refs)
all.raw = clean_txt(c(all.refs, essays))
Z = c(rep(1,n.refs), rep(0,length(essays))) # Indicator for reference texts
dfm1 = quanteda::tokens(all.raw) |>
  quanteda::dfm(valuetype="fixed", stem=F)
tdm.dists = textmatch::pair_distances(dfm1, Z, include="cosine", form="data.frame")
all.dists = tdm.dists[with(tdm.dists,order(index.0, as.numeric(index.1))),]
names(all.dists)[grep("cosine",names(all.dists))]="tdm.raw.cosine"


# Calculate Word2Vec projections for each reference text on 50 dimensions
proj = tada::extract_w2v( clean_text(text$text.sc), # projections for essay texts
                               model = glove.50d )
proj.refs = tada::extract_w2v( clean_text(all.refs), # projections for reference texts
                               model = glove.50d )

proj.all = rbind(proj.refs, proj)

#proj.all <- mapply(c, proj.refs, proj)

W2V.dists = textmatch::pair_distances(proj.all, Z, include="cosine",form="data.frame")
W2V.dists = W2V.dists[with(W2V.dists, order(index.0, as.numeric(index.1))),]
names(W2V.dists)[3]="glove.d50.cosine"
all.dists = merge(all.dists, W2V.dists, by=c("index.1","index.0"))


refs = data.frame(index.0=1:n.refs, name=ref.names)
all.dists = merge(all.dists,refs, by=c("index.0"))
all.dists = all.dists[with(all.dists,order(index.1,index.0)),]

tmp = subset(meta, select=c(s_id, subject, grade))
tmp$MID = (1:nrow(tmp))+n.refs # temporary ID for merging
all2 = merge(tmp, all.dists, by.x="MID", by.y="index.1")

sci.g1 = subset(all2[all2$subject=="science" & all2$grade==1 & all2$name=="G1.sci.both",],select=-c(MID, index.0, name))
soc.g1 = subset(all2[all2$subject=="social" & all2$grade==1 & all2$name=="G1.soc.both",],select=-c(MID, index.0, name))

sci.g2 = subset(all2[all2$subject=="science" & all2$grade==2 & all2$name=="G2.sci",],select=-c(MID, index.0, name))
soc.g2 = subset(all2[all2$subject=="social" & all2$grade==2 & all2$name=="G2.soc.both",],select=-c(MID, index.0, name))

table(meta$grade,meta$subject)

all.dists = rbind(sci.g1, soc.g1, sci.g2, soc.g2)
rownames(all.dists)=NULL

# Merge with existing feature set
all.info = merge(all.dists, all.feats, by=c("s_id","grade","subject"))
gdata::keep(all.info, text, meta, sure=T)

# Add output from TAACO

add <- read.csv("data-generated/taaco_main.csv")
colnames(add)[colnames(add)!="Filename"] = paste0( "taaco_", colnames(add)[colnames(add)!="Filename"] )
add$s_id = sapply(1:nrow(add),function(x)as.numeric(gsub("s","",strsplit(add$Filename[x], "_", fixed=T)[[1]][1])))
add$grade = sapply(1:nrow(add),function(x)as.numeric(gsub("grade","",strsplit(add$Filename[x], "_", fixed=T)[[1]][2])))
add$subject = sapply(1:nrow(add),function(x)gsub(".txt","",strsplit(add$Filename[x], "_", fixed=T)[[1]][3]))

add = dplyr::select(add, s_id, grade, subject, everything(), -Filename)

all.info2 = merge(all.info, add, by=c("s_id","grade","subject"))

all.info = all.info2 %>% select(-ends_with("_para"), -ends_with("_div_seg"))

dim(all.info)
table(apply(all.info,2,anyNA))


all.info = merge(meta, all.info, by=c("s_id","subject", "grade"))


all.info = all.info[with(all.info,order(s_id,subject)),]
save(all.info, file="data-generated/all.info.RData")
